{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a488b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, math, time, csv\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "plt.switch_backend(\"agg\")\n",
    "\n",
    "TRAIN_ROOT = \"cleaned/Training\"\n",
    "TEST_ROOT  = \"cleaned/Testing\"\n",
    "OUTDIR     = \"runs/vit64\"\n",
    "SAVE_NAME  = \"vit64_best.pt\"\n",
    "\n",
    "EPOCHS       = 30\n",
    "BATCH_SIZE   = 64\n",
    "LR           = 3e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "WORKERS      = 4\n",
    "PATIENCE     = 8\n",
    "SEED         = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef17166",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEmbed(nn.Module):\n",
    "    def __init__(self, in_ch=3, dim=128, patch=8):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Conv2d(in_ch, dim, kernel_size=patch, stride=patch, bias=False)\n",
    "    def forward(self, x):\n",
    "        x = self.proj(x)\n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "class ViT64(nn.Module):\n",
    "    def __init__(self, num_classes=4, img_size=64, patch=8, dim=128, depth=6, heads=4, mlp_ratio=4, drop=0.1, in_ch=3):\n",
    "        super().__init__()\n",
    "        assert img_size % patch == 0\n",
    "        self.num_patches = (img_size // patch) ** 2\n",
    "        self.dim = dim\n",
    "\n",
    "        self.patch_embed = PatchEmbed(in_ch, dim, patch)\n",
    "        self.cls_token = nn.Parameter(torch.zeros(1, 1, dim))\n",
    "        self.pos_embed = nn.Parameter(torch.randn(1, self.num_patches + 1, dim) * 0.02)\n",
    "        self.pos_drop = nn.Dropout(drop)\n",
    "\n",
    "        enc_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=dim, nhead=heads, dim_feedforward=dim * mlp_ratio,\n",
    "            dropout=drop, batch_first=True, activation=\"gelu\", norm_first=True\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(enc_layer, num_layers=depth)\n",
    "        self.norm = nn.LayerNorm(dim, eps=1e-6)\n",
    "        self.head = nn.Linear(dim, num_classes)\n",
    "        self.register_buffer(\"eps\", torch.tensor(1e-6), persistent=False)\n",
    "\n",
    "    def zscore(self, x):\n",
    "        mean = x.mean(dim=[2,3], keepdim=True)\n",
    "        std  = x.std(dim=[2,3], keepdim=True) + self.eps\n",
    "        return (x - mean) / std\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.zscore(x)\n",
    "        x = self.patch_embed(x)\n",
    "        B, N, _ = x.shape\n",
    "        cls = self.cls_token.expand(B, 1, self.dim)\n",
    "        x = torch.cat([cls, x], dim=1)\n",
    "        x = x + self.pos_embed\n",
    "        x = self.pos_drop(x)\n",
    "        x = self.encoder(x)\n",
    "        x = self.norm(x)\n",
    "        return self.head(x[:, 0])\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    import random\n",
    "    random.seed(seed); np.random.seed(seed)\n",
    "    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def make_transforms():\n",
    "    train_tf = transforms.Compose([\n",
    "        transforms.RandomHorizontalFlip(0.5),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    val_tf = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    return train_tf, val_tf\n",
    "\n",
    "def stratified_split_indices(targets, train_frac=0.8, seed=42):\n",
    "    targets = np.array(targets)\n",
    "    classes = np.unique(targets)\n",
    "    rng = np.random.default_rng(seed)\n",
    "    train_idx, val_idx = [], []\n",
    "    for c in classes:\n",
    "        idx = np.where(targets == c)[0]\n",
    "        rng.shuffle(idx)\n",
    "        n_train = int(round(len(idx) * train_frac))\n",
    "        train_idx.extend(idx[:n_train])\n",
    "        val_idx.extend(idx[n_train:])\n",
    "    rng.shuffle(train_idx); rng.shuffle(val_idx)\n",
    "    return train_idx, val_idx\n",
    "\n",
    "def class_weights_from_indices(targets, idx):\n",
    "    t = torch.tensor(np.array(targets)[idx])\n",
    "    K = int(t.max().item() + 1)\n",
    "    counts = torch.bincount(t, minlength=K).float()\n",
    "    w = (counts.sum() / (counts + 1e-6))\n",
    "    return (w / w.mean())\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    ce = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "    loss_sum, correct, total = 0.0, 0, 0\n",
    "    all_y, all_p = [], []\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        logits = model(x)\n",
    "        loss_sum += ce(logits, y).item()\n",
    "        pred = logits.argmax(1)\n",
    "        correct += (pred == y).sum().item()\n",
    "        total += y.numel()\n",
    "        all_y.append(y.cpu()); all_p.append(pred.cpu())\n",
    "    y_true = torch.cat(all_y).numpy()\n",
    "    y_pred = torch.cat(all_p).numpy()\n",
    "    return loss_sum / total, correct / total, y_true, y_pred\n",
    "\n",
    "def plot_curves(history, outdir):\n",
    "    outdir = Path(outdir); outdir.mkdir(parents=True, exist_ok=True)\n",
    "    csv_path = outdir / \"history.csv\"\n",
    "    with open(csv_path, \"w\", newline=\"\") as f:\n",
    "        wr = csv.writer(f); wr.writerow([\"epoch\",\"train_loss\",\"train_acc\",\"val_loss\",\"val_acc\"])\n",
    "        for i in range(len(history[\"epoch\"])):\n",
    "            wr.writerow([history[k][i] for k in [\"epoch\",\"train_loss\",\"train_acc\",\"val_loss\",\"val_acc\"]])\n",
    "\n",
    "    e = history[\"epoch\"]\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.plot(e, history[\"train_loss\"], label=\"train\")\n",
    "    plt.plot(e, history[\"val_loss\"],   label=\"val\")\n",
    "    plt.xlabel(\"epoch\"); plt.ylabel(\"loss\"); plt.legend(); plt.tight_layout()\n",
    "    plt.savefig(outdir/\"loss.png\"); plt.close()\n",
    "\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.plot(e, history[\"train_acc\"], label=\"train\")\n",
    "    plt.plot(e, history[\"val_acc\"],   label=\"val\")\n",
    "    plt.xlabel(\"epoch\"); plt.ylabel(\"accuracy\"); plt.legend(); plt.tight_layout()\n",
    "    plt.savefig(outdir/\"acc.png\"); plt.close()\n",
    "\n",
    "def plot_confusion(y_true, y_pred, class_names, outpath):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=list(range(len(class_names))))\n",
    "    cm = cm.astype(np.int32)\n",
    "    plt.figure(figsize=(5,5))\n",
    "    plt.imshow(cm, interpolation=\"nearest\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.xticks(range(len(class_names)), class_names, rotation=45, ha=\"right\")\n",
    "    plt.yticks(range(len(class_names)), class_names)\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, str(cm[i, j]), ha=\"center\", va=\"center\")\n",
    "    plt.xlabel(\"Predicted\"); plt.ylabel(\"True\"); plt.tight_layout()\n",
    "    plt.savefig(outpath); plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e680a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Classes: ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
      "Epoch 001 |  75.9s | train 1.1898/0.4348 | val 1.0123/0.5464\n",
      "  → saved best to runs\\vit64\\vit64_best.pt\n",
      "Epoch 002 |  60.4s | train 0.9262/0.5875 | val 0.9178/0.6532\n",
      "  → saved best to runs\\vit64\\vit64_best.pt\n",
      "Epoch 003 |  64.1s | train 0.7803/0.6757 | val 0.8366/0.6454\n",
      "  → saved best to runs\\vit64\\vit64_best.pt\n",
      "Epoch 004 |  62.0s | train 0.7328/0.6958 | val 0.6680/0.7469\n",
      "  → saved best to runs\\vit64\\vit64_best.pt\n",
      "Epoch 005 |  58.3s | train 0.6322/0.7455 | val 0.5591/0.7863\n",
      "  → saved best to runs\\vit64\\vit64_best.pt\n",
      "Epoch 006 |  58.1s | train 0.6383/0.7530 | val 0.6363/0.7452\n",
      "Epoch 007 |  58.4s | train 0.5925/0.7659 | val 0.6041/0.7338\n",
      "Epoch 008 |  65.0s | train 0.5537/0.7875 | val 0.4403/0.8389\n",
      "  → saved best to runs\\vit64\\vit64_best.pt\n",
      "Epoch 009 |  58.1s | train 0.5421/0.7790 | val 0.4144/0.8415\n",
      "  → saved best to runs\\vit64\\vit64_best.pt\n",
      "Epoch 010 |  58.0s | train 0.5429/0.7862 | val 0.4904/0.8074\n",
      "Epoch 011 |  58.1s | train 0.5175/0.7985 | val 0.4977/0.8065\n",
      "Epoch 012 |  58.2s | train 0.4936/0.8096 | val 0.4757/0.7907\n",
      "Epoch 013 |  64.9s | train 0.4811/0.8151 | val 0.3863/0.8450\n",
      "  → saved best to runs\\vit64\\vit64_best.pt\n",
      "Epoch 014 |  63.5s | train 0.4654/0.8140 | val 0.5149/0.7986\n",
      "Epoch 015 |  63.1s | train 0.4642/0.8199 | val 0.3851/0.8546\n",
      "  → saved best to runs\\vit64\\vit64_best.pt\n",
      "Epoch 016 |  64.1s | train 0.4592/0.8210 | val 0.3482/0.8757\n",
      "  → saved best to runs\\vit64\\vit64_best.pt\n",
      "Epoch 017 |  62.8s | train 0.4490/0.8223 | val 0.3688/0.8581\n",
      "Epoch 018 |  63.0s | train 0.4336/0.8317 | val 0.5440/0.7723\n",
      "Epoch 019 |  63.8s | train 0.4283/0.8370 | val 0.3729/0.8494\n",
      "Epoch 020 |  62.4s | train 0.4145/0.8383 | val 0.3640/0.8599\n",
      "Epoch 021 |  63.4s | train 0.3831/0.8527 | val 0.4685/0.8091\n",
      "Epoch 022 |  62.5s | train 0.3546/0.8667 | val 0.3707/0.8616\n",
      "Epoch 023 |  62.4s | train 0.3534/0.8628 | val 0.3519/0.8669\n",
      "Epoch 024 |  62.9s | train 0.3425/0.8694 | val 0.3413/0.8695\n",
      "  → saved best to runs\\vit64\\vit64_best.pt\n",
      "Epoch 025 |  62.6s | train 0.3483/0.8659 | val 0.2934/0.8870\n",
      "  → saved best to runs\\vit64\\vit64_best.pt\n",
      "Epoch 026 |  63.0s | train 0.3287/0.8761 | val 0.3070/0.8897\n",
      "Epoch 027 |  62.2s | train 0.3201/0.8777 | val 0.3308/0.8730\n",
      "Epoch 028 |  63.6s | train 0.3308/0.8751 | val 0.3051/0.8809\n",
      "Epoch 029 |  63.5s | train 0.3104/0.8851 | val 0.2814/0.8914\n",
      "  → saved best to runs\\vit64\\vit64_best.pt\n",
      "Epoch 030 |  63.2s | train 0.3092/0.8853 | val 0.3126/0.8783\n",
      "TEST   loss 0.3410  acc 0.8604\n",
      "Saved confusion matrix to runs\\vit64\\confusion_test.png\n",
      "History CSV / curves saved to runs\\vit64\n"
     ]
    }
   ],
   "source": [
    "set_seed(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "train_tf, val_tf = make_transforms()\n",
    "\n",
    "full_train = datasets.ImageFolder(TRAIN_ROOT, transform=train_tf)\n",
    "test_ds    = datasets.ImageFolder(TEST_ROOT,  transform=val_tf)\n",
    "classes = full_train.classes\n",
    "print(\"Classes:\", classes)\n",
    "\n",
    "train_idx, val_idx = stratified_split_indices(full_train.targets, train_frac=0.8, seed=SEED)\n",
    "train_ds = Subset(full_train, train_idx)\n",
    "val_base = datasets.ImageFolder(TRAIN_ROOT, transform=val_tf)\n",
    "val_ds = Subset(val_base, val_idx)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=WORKERS, pin_memory=True)\n",
    "val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                          num_workers=WORKERS, pin_memory=True)\n",
    "test_loader  = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                          num_workers=WORKERS, pin_memory=True)\n",
    "\n",
    "# Model, loss, opt\n",
    "model = ViT64(num_classes=len(classes), in_ch=3).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "sched = torch.optim.lr_scheduler.ReduceLROnPlateau(opt, factor=0.5, patience=3)\n",
    "\n",
    "outdir = Path(OUTDIR); outdir.mkdir(parents=True, exist_ok=True)\n",
    "ckpt_path = outdir / SAVE_NAME\n",
    "\n",
    "best_val = math.inf\n",
    "patience_ctr = 0\n",
    "history = {\"epoch\":[], \"train_loss\":[], \"train_acc\":[], \"val_loss\":[], \"val_acc\":[]}\n",
    "\n",
    "scaler = torch.amp.GradScaler(\"cuda\", enabled=(device.type == \"cuda\"))\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    t0 = time.time()\n",
    "    run_loss, run_correct, run_total = 0.0, 0, 0\n",
    "\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        opt.zero_grad(set_to_none=True)\n",
    "        with torch.amp.autocast(\"cuda\", enabled=(device.type == \"cuda\")):\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(opt)\n",
    "        scaler.update()\n",
    "\n",
    "        run_loss += loss.item() * y.size(0)\n",
    "        run_correct += (logits.argmax(1) == y).sum().item()\n",
    "        run_total += y.size(0)\n",
    "\n",
    "    train_loss = run_loss / run_total\n",
    "    train_acc  = run_correct / run_total\n",
    "\n",
    "    val_loss, val_acc, _, _ = evaluate(model, val_loader, device)\n",
    "    sched.step(val_loss)\n",
    "\n",
    "    history[\"epoch\"].append(epoch)\n",
    "    history[\"train_loss\"].append(train_loss)\n",
    "    history[\"train_acc\"].append(train_acc)\n",
    "    history[\"val_loss\"].append(val_loss)\n",
    "    history[\"val_acc\"].append(val_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch:03d} | {time.time()-t0:5.1f}s | \"\n",
    "          f\"train {train_loss:.4f}/{train_acc:.4f} | \"\n",
    "          f\"val {val_loss:.4f}/{val_acc:.4f}\")\n",
    "\n",
    "    if val_loss + 1e-6 < best_val:\n",
    "        best_val = val_loss\n",
    "        patience_ctr = 0\n",
    "        torch.save({\"model\": model.state_dict(), \"classes\": classes}, ckpt_path)\n",
    "        print(f\"  → saved best to {ckpt_path}\")\n",
    "    else:\n",
    "        patience_ctr += 1\n",
    "        if patience_ctr >= PATIENCE:\n",
    "            print(f\"Early stopping (best val loss {best_val:.4f})\")\n",
    "            break\n",
    "\n",
    "plot_curves(history, outdir)\n",
    "\n",
    "ckpt = torch.load(ckpt_path, map_location=device)\n",
    "model.load_state_dict(ckpt[\"model\"])\n",
    "test_loss, test_acc, y_true, y_pred = evaluate(model, test_loader, device)\n",
    "print(f\"TEST   loss {test_loss:.4f}  acc {test_acc:.4f}\")\n",
    "\n",
    "plot_confusion(y_true, y_pred, classes, outdir/\"confusion_test.png\")\n",
    "print(f\"Saved confusion matrix to {outdir/'confusion_test.png'}\")\n",
    "print(f\"History CSV / curves saved to {outdir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f51f869c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image counts per class:\n",
      "  Train: {'glioma': 1057, 'meningioma': 1071, 'notumor': 1276, 'pituitary': 1166}\n",
      "  Val:   {'glioma': 264, 'meningioma': 268, 'notumor': 319, 'pituitary': 291}\n",
      "  Test:  {'glioma': 300, 'meningioma': 306, 'notumor': 405, 'pituitary': 300}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "def count_split(dataset, class_names):\n",
    "    targets = np.array(dataset.dataset.targets)[dataset.indices] if isinstance(dataset, Subset) else np.array(dataset.targets)\n",
    "    counts = Counter(targets)\n",
    "    return {class_names[i]: counts.get(i, 0) for i in range(len(class_names))}\n",
    "\n",
    "print(\"Image counts per class:\")\n",
    "print(\"  Train:\", count_split(train_ds, classes))\n",
    "print(\"  Val:  \", count_split(val_ds, classes))\n",
    "print(\"  Test: \", count_split(test_ds, classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6656245c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 1,223,428\n",
      "Trainable parameters: 1,223,428\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
